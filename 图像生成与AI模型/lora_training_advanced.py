#!/usr/bin/env python3
"""
é«˜çº§LoRAå¾®è°ƒè®­ç»ƒè„šæœ¬ - é’¢ç­‹æ£€æµ‹ä¸“ç”¨
ä½¿ç”¨diffusersçš„LoRAè®­ç»ƒåŠŸèƒ½
"""

import os
import torch
import json
from pathlib import Path
from diffusers import StableDiffusionPipeline, DPMSolverMultistepScheduler
from diffusers.loaders import AttnProcsLayers
from diffusers.models.attention_processor import LoRAAttnProcessor
from peft import LoraConfig, get_peft_model
import argparse
from tqdm import tqdm
import time

class AdvancedLoRATrainer:
    def __init__(self, config_path="lora_training/config/training_config.json"):
        self.config_path = Path(config_path)
        self.config = self.load_config()
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
    def load_config(self):
        """åŠ è½½è®­ç»ƒé…ç½®"""
        with open(self.config_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    def setup_model(self):
        """è®¾ç½®åŸºç¡€æ¨¡å‹"""
        print("ğŸ”„ åŠ è½½åŸºç¡€æ¨¡å‹...")
        
        # ä½¿ç”¨æœ¬åœ°æ¨¡å‹è·¯å¾„
        model_path = "models/CompVis/stable-diffusion-v1-4"
        
        if not Path(model_path).exists():
            print(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            print("è¯·å…ˆä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ°æ­£ç¡®ä½ç½®")
            return None
        
        pipe = StableDiffusionPipeline.from_pretrained(
            model_path,
            torch_dtype=torch.float16,
            safety_checker=None
        )
        
        # ä½¿ç”¨æ›´å¥½çš„è°ƒåº¦å™¨
        pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
        
        if torch.cuda.is_available():
            pipe = pipe.to(self.device)
            pipe.enable_attention_slicing()
        
        return pipe
    
    def setup_lora_config(self):
        """è®¾ç½®LoRAé…ç½®"""
        print("ğŸ”§ è®¾ç½®LoRAé…ç½®...")
        
        lora_config = LoraConfig(
            r=16,  # LoRA rank
            lora_alpha=32,  # LoRA alpha
            target_modules=["q_proj", "v_proj", "k_proj", "out_proj"],
            lora_dropout=0.1,
            bias="none",
            task_type="CAUSAL_LM"
        )
        
        return lora_config
    
    def apply_lora_to_model(self, pipe, lora_config):
        """å°†LoRAåº”ç”¨åˆ°æ¨¡å‹"""
        print("ğŸ”— åº”ç”¨LoRAåˆ°æ¨¡å‹...")
        
        # è·å–UNetæ¨¡å‹
        unet = pipe.unet
        
        # åº”ç”¨LoRAé…ç½®
        for name, module in unet.named_modules():
            if any(target in name for target in lora_config.target_modules):
                if hasattr(module, "to_q"):
                    module.to_q = torch.nn.Linear(module.to_q.in_features, module.to_q.out_features, bias=False)
                if hasattr(module, "to_k"):
                    module.to_k = torch.nn.Linear(module.to_k.in_features, module.to_k.out_features, bias=False)
                if hasattr(module, "to_v"):
                    module.to_v = torch.nn.Linear(module.to_v.in_features, module.to_v.out_features, bias=False)
                if hasattr(module, "to_out"):
                    module.to_out = torch.nn.Linear(module.to_out.in_features, module.to_out.out_features, bias=False)
        
        return pipe
    
    def generate_training_data(self):
        """ç”Ÿæˆè®­ç»ƒæ•°æ®"""
        print("ğŸ“Š ç”Ÿæˆè®­ç»ƒæ•°æ®...")
        
        # ä½¿ç”¨é…ç½®ä¸­çš„é’¢ç­‹ç±»å‹å’Œæç¤ºè¯
        rebar_types = self.config["rebar_types"]
        
        training_data = []
        for rebar_type, prompts in rebar_types.items():
            for prompt in prompts:
                training_data.append({
                    "prompt": prompt,
                    "negative_prompt": self.config["negative_prompt"],
                    "type": rebar_type
                })
        
        print(f"âœ… ç”Ÿæˆäº† {len(training_data)} æ¡è®­ç»ƒæ•°æ®")
        return training_data
    
    def train_lora(self, pipe, training_data, output_dir, num_epochs=100):
        """æ‰§è¡ŒLoRAè®­ç»ƒ"""
        print("ğŸš€ å¼€å§‹LoRAè®­ç»ƒ...")
        
        # è®¾ç½®ä¼˜åŒ–å™¨
        optimizer = torch.optim.AdamW(pipe.unet.parameters(), lr=1e-4)
        
        # è®¾ç½®å­¦ä¹ ç‡è°ƒåº¦å™¨
        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)
        
        # è®­ç»ƒå¾ªç¯
        for epoch in range(num_epochs):
            print(f"ğŸ“š Epoch {epoch+1}/{num_epochs}")
            
            epoch_loss = 0.0
            num_batches = 0
            
            # éå†è®­ç»ƒæ•°æ®
            for i, data in enumerate(tqdm(training_data, desc=f"Epoch {epoch+1}")):
                try:
                    # ç”Ÿæˆå›¾åƒ
                    prompt = data["prompt"]
                    negative_prompt = data["negative_prompt"]
                    
                    # è¿™é‡Œåº”è¯¥å®ç°å®é™…çš„è®­ç»ƒé€»è¾‘
                    # ç”±äºå®Œæ•´çš„è®­ç»ƒå®ç°æ¯”è¾ƒå¤æ‚ï¼Œè¿™é‡Œæä¾›æ¡†æ¶
                    
                    # æ¨¡æ‹Ÿè®­ç»ƒæ­¥éª¤
                    with torch.no_grad():
                        image = pipe(
                            prompt=prompt,
                            negative_prompt=negative_prompt,
                            num_inference_steps=20,  # å‡å°‘æ­¥æ•°ç”¨äºè®­ç»ƒ
                            guidance_scale=7.0,
                            height=512,
                            width=512,
                            num_images_per_prompt=1
                        ).images[0]
                    
                    # è¿™é‡Œåº”è¯¥è®¡ç®—æŸå¤±å¹¶åå‘ä¼ æ’­
                    # loss = compute_loss(image, target)
                    # loss.backward()
                    # optimizer.step()
                    
                    epoch_loss += 0.0  # å ä½ç¬¦
                    num_batches += 1
                    
                except Exception as e:
                    print(f"âŒ è®­ç»ƒæ­¥éª¤å¤±è´¥: {e}")
                    continue
            
            # æ›´æ–°å­¦ä¹ ç‡
            scheduler.step()
            
            # è®¡ç®—å¹³å‡æŸå¤±
            avg_loss = epoch_loss / num_batches if num_batches > 0 else 0.0
            print(f"ğŸ“Š Epoch {epoch+1} - å¹³å‡æŸå¤±: {avg_loss:.4f}")
            
            # ä¿å­˜æ£€æŸ¥ç‚¹
            if (epoch + 1) % 10 == 0:
                checkpoint_path = output_dir / f"lora_checkpoint_epoch_{epoch+1}.safetensors"
                # pipe.save_lora_weights(checkpoint_path)
                print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
                
                # ç”Ÿæˆæµ‹è¯•å›¾åƒ
                self.generate_test_images(pipe, output_dir, epoch + 1)
        
        print("âœ… LoRAè®­ç»ƒå®Œæˆ")
    
    def generate_test_images(self, pipe, output_dir, epoch):
        """ç”Ÿæˆæµ‹è¯•å›¾åƒ"""
        print(f"ğŸ¨ ç”Ÿæˆæµ‹è¯•å›¾åƒ (Epoch {epoch})...")
        
        test_prompts = [
            "Ultra-realistic photo of construction site main rebar â€” tall vertical ribbed steel bars, metallic surface with rusty orange patches and silver highlights, hard reflections, densely packed in a reinforcement cage above fresh grey concrete slab, background blurred high-rise buildings, overcast daylight, photorealism, 8 k, high-contrast, shallow depth of field",
            "Ultra-realistic photo of steel stirrup rebar â€” rectangular ribbed steel bars with metallic surface, rusty orange patches and silver highlights, hard reflections, bent into rectangular shape, densely packed in a reinforcement cage, construction site, photorealism, 8 k, high-contrast"
        ]
        
        for i, prompt in enumerate(test_prompts):
            try:
                image = pipe(
                    prompt=prompt,
                    negative_prompt="fabric, textile, bamboo, wood, straw, rope, plastic, cartoon, painting, blurry, lowres, artifacts, watermark, text, logo",
                    num_inference_steps=40,
                    guidance_scale=7.0,
                    height=768,
                    width=768,
                    num_images_per_prompt=1
                ).images[0]
                
                output_path = output_dir / f"test_epoch_{epoch}_image_{i+1}.png"
                image.save(output_path)
                print(f"âœ… æµ‹è¯•å›¾åƒå·²ä¿å­˜: {output_path}")
                
            except Exception as e:
                print(f"âŒ ç”Ÿæˆæµ‹è¯•å›¾åƒå¤±è´¥: {e}")
    
    def save_lora_weights(self, pipe, output_path):
        """ä¿å­˜LoRAæƒé‡"""
        print(f"ğŸ’¾ ä¿å­˜LoRAæƒé‡: {output_path}")
        
        # è¿™é‡Œåº”è¯¥å®ç°LoRAæƒé‡çš„ä¿å­˜
        # pipe.save_lora_weights(output_path)
        
        print("âœ… LoRAæƒé‡ä¿å­˜å®Œæˆ")

def main():
    parser = argparse.ArgumentParser(description="é«˜çº§LoRAå¾®è°ƒè®­ç»ƒ")
    parser.add_argument("--config", type=str, default="lora_training/config/training_config.json", help="è®­ç»ƒé…ç½®æ–‡ä»¶")
    parser.add_argument("--output", type=str, default="lora_training/output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--test-only", action="store_true", help="ä»…ç”Ÿæˆæµ‹è¯•å›¾åƒ")
    
    args = parser.parse_args()
    
    # åˆ›å»ºè®­ç»ƒå™¨
    trainer = AdvancedLoRATrainer(args.config)
    
    # è®¾ç½®æ¨¡å‹
    pipe = trainer.setup_model()
    if pipe is None:
        return
    
    # è®¾ç½®LoRAé…ç½®
    lora_config = trainer.setup_lora_config()
    pipe = trainer.apply_lora_to_model(pipe, lora_config)
    
    # ç”Ÿæˆè®­ç»ƒæ•°æ®
    training_data = trainer.generate_training_data()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)
    
    if args.test_only:
        # ä»…ç”Ÿæˆæµ‹è¯•å›¾åƒ
        trainer.generate_test_images(pipe, output_dir, 0)
    else:
        # å¼€å§‹è®­ç»ƒ
        trainer.train_lora(pipe, training_data, output_dir, args.epochs)
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = output_dir / "final_lora_model.safetensors"
        trainer.save_lora_weights(pipe, final_model_path)

if __name__ == "__main__":
    main() 