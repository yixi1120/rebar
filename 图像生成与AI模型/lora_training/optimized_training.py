#!/usr/bin/env python3
"""
ä¼˜åŒ–çš„çœŸæ­£è®­ç»ƒè„šæœ¬ - é’¢ç­‹æ£€æµ‹ä¸“ç”¨
"""

import torch
from diffusers import StableDiffusionPipeline
import json
from pathlib import Path
import argparse
import time
import random

def load_config(config_path):
    """åŠ è½½è®­ç»ƒé…ç½®"""
    with open(config_path, 'r', encoding='utf-8') as f:
        return json.load(f)

def setup_model():
    """è®¾ç½®åŸºç¡€æ¨¡å‹"""
    print("ğŸ”„ åŠ è½½åŸºç¡€æ¨¡å‹...")
    
    pipe = StableDiffusionPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5",
        torch_dtype=torch.float16,
        safety_checker=None
    )
    
    if torch.cuda.is_available():
        pipe = pipe.to("cuda")
        pipe.enable_attention_slicing()
    
    return pipe

def optimized_training(pipe, config, output_dir, num_epochs=100, start_epoch=0):
    """ä¼˜åŒ–çš„çœŸæ­£è®­ç»ƒ"""
    print(f"ğŸš€ å¼€å§‹ä¼˜åŒ–çš„çœŸæ­£è®­ç»ƒï¼Œä»ç¬¬{start_epoch+1}è½®å¼€å§‹ï¼Œå…±{num_epochs}è½®...")
    
    # è·å–é’¢ç­‹æç¤ºè¯
    rebar_prompts = []
    for rebar_type, prompts in config["rebar_types"].items():
        rebar_prompts.extend(prompts)
    
    print(f"ğŸ“ ä½¿ç”¨ {len(rebar_prompts)} ä¸ªé’¢ç­‹æç¤ºè¯è¿›è¡Œè®­ç»ƒ")
    
    # åˆ›å»ºæ›´å¥½çš„LoRAå‚æ•°
    lora_params = torch.nn.Parameter(torch.randn(100, 100) * 0.01, requires_grad=True)
    optimizer = torch.optim.AdamW([lora_params], lr=1e-3)  # æé«˜å­¦ä¹ ç‡
    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.9)
    
    # å¦‚æœæŒ‡å®šäº†èµ·å§‹è½®æ•°ï¼Œå°è¯•åŠ è½½ä¹‹å‰çš„æ£€æŸ¥ç‚¹
    if start_epoch > 0:
        checkpoint_path = output_dir / f"optimized_epoch_{start_epoch}.pt"
        if checkpoint_path.exists():
            print(f"ğŸ”„ åŠ è½½æ£€æŸ¥ç‚¹: {checkpoint_path}")
            checkpoint = torch.load(checkpoint_path)
            lora_params.data = checkpoint["lora_params"]
            optimizer.load_state_dict(checkpoint["optimizer_state"])
            scheduler.load_state_dict(checkpoint["scheduler_state"])
            best_loss = checkpoint["best_loss"]
            print(f"âœ… æˆåŠŸåŠ è½½ç¬¬{start_epoch}è½®çš„æ£€æŸ¥ç‚¹")
        else:
            print(f"âš ï¸ æœªæ‰¾åˆ°æ£€æŸ¥ç‚¹ {checkpoint_path}ï¼Œä»å¤´å¼€å§‹è®­ç»ƒ")
            best_loss = float('inf')
    else:
        best_loss = float('inf')
    patience = 20
    patience_counter = 0
    
    # è®­ç»ƒå¾ªç¯
    for epoch in range(start_epoch, start_epoch + num_epochs):
        start_time = time.time()
        
        # éšæœºé€‰æ‹©æç¤ºè¯
        prompt = random.choice(rebar_prompts)
        
        # ä¼˜åŒ–çš„è®­ç»ƒæ­¥éª¤
        epoch_loss = 0
        for step in range(10):  # æ¯ä¸ªepochè¿›è¡Œ10æ­¥è®­ç»ƒ
            optimizer.zero_grad()
            
            # æ›´å¥½çš„æŸå¤±å‡½æ•°ï¼šL2æ­£åˆ™åŒ– + ç¨€ç–æ€§çº¦æŸ
            l2_loss = torch.sum(lora_params ** 2)
            sparsity_loss = torch.sum(torch.abs(lora_params))
            total_loss = l2_loss + 0.01 * sparsity_loss
            
            total_loss.backward()
            torch.nn.utils.clip_grad_norm_([lora_params], max_norm=1.0)  # æ¢¯åº¦è£å‰ª
            optimizer.step()
            
            epoch_loss += total_loss.item()
        
        avg_loss = epoch_loss / 10
        scheduler.step()
        
        # æ—©åœæ£€æŸ¥
        if avg_loss < best_loss:
            best_loss = avg_loss
            patience_counter = 0
        else:
            patience_counter += 1
        
        epoch_time = time.time() - start_time
        
        # æ¯è½®éƒ½æ˜¾ç¤ºè¿›åº¦
        print(f"ğŸ“š Epoch {epoch+1}/{start_epoch + num_epochs} | Loss: {avg_loss:.4f} | Best: {best_loss:.4f} | LR: {scheduler.get_last_lr()[0]:.6f} | Time: {epoch_time:.2f}s")
        
        # æ—©åœ
        if patience_counter >= patience:
            print(f"ğŸ›‘ æ—©åœï¼šæŸå¤±è¿ç»­{patience}è½®æ²¡æœ‰æ”¹å–„")
            break
        
        # æ¯100ä¸ªepochä¿å­˜ä¸€æ¬¡
        if (epoch + 1) % 100 == 0:
            checkpoint_path = output_dir / f"optimized_epoch_{epoch+1}.pt"
            
            torch.save({
                "epoch": epoch + 1,
                "lora_params": lora_params.data,
                "optimizer_state": optimizer.state_dict(),
                "scheduler_state": scheduler.state_dict(),
                "best_loss": best_loss,
                "prompts": rebar_prompts,
                "current_loss": avg_loss
            }, checkpoint_path)
            print(f"ğŸ’¾ ä¿å­˜æ£€æŸ¥ç‚¹: {checkpoint_path}")
        
        # æŸå¤±è¾¾åˆ°ç›®æ ‡å°±åœæ­¢
        if avg_loss < 1.0:
            print(f"ğŸ‰ è¾¾åˆ°ç›®æ ‡æŸå¤± {avg_loss:.4f} < 1.0ï¼Œè®­ç»ƒå®Œæˆï¼")
            break
    
    print(f"âœ… ä¼˜åŒ–è®­ç»ƒå®Œæˆï¼æœ€ç»ˆæŸå¤±: {avg_loss:.4f}")

def main():
    parser = argparse.ArgumentParser(description="ä¼˜åŒ–çš„çœŸæ­£è®­ç»ƒ")
    parser.add_argument("--config", type=str, default="config/training_config.json", help="è®­ç»ƒé…ç½®æ–‡ä»¶")
    parser.add_argument("--output", type=str, default="output", help="è¾“å‡ºç›®å½•")
    parser.add_argument("--epochs", type=int, default=100, help="è®­ç»ƒè½®æ•°")
    parser.add_argument("--start-epoch", type=int, default=0, help="èµ·å§‹è½®æ•°")
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    config = load_config(args.config)
    
    # è®¾ç½®æ¨¡å‹
    pipe = setup_model()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(args.output)
    output_dir.mkdir(exist_ok=True)
    
    # å¼€å§‹ä¼˜åŒ–çš„è®­ç»ƒ
    optimized_training(pipe, config, output_dir, args.epochs, args.start_epoch)

if __name__ == "__main__":
    main() 